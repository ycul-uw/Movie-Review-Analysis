{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('movie.csv') # Pandas already has handy functions/methods for reading CSVs\n",
    "# That's it! \"df\" here is short for \"dataframe\", a.k.a. a fancy spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0\n",
       "2  Why do people who do not know what a particula...      0\n",
       "3  Even though I have great interest in Biblical ...      0\n",
       "4  Im a die hard Dads Army fan and nothing will e...      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will show the first 5 rows in the spreadsheet so we can see what we're working with:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 16061 - Label: 1 (Positive))\n",
      "Being in the suburbs of New York when the Z-Boys were creating history in Dogtown, I was only exposed to a glimpse of what was going on. I had a P-O-S Black Knight skateboard with clay wheels. It is long gone, and on the ash heap of my personal life. But I never forgot. It's like watching long-lost brothers and friends, and it hits me right where I live. I cannot watch this film enough. Every time I view it, some other aspect rises to the top, some other viewpoint come into sharp focus. The vintage footage, the incredible stills, the current personalities intermeshed with the vivid shadows of the brightly lit past, the heartfelt and not over-done narrative, all beautifully edited together in such a way as to make a landmark documentary of a genuine slice of American history. In the words of Glen Friedman - \"It was F-ing unbelievable.\"\n",
      "\n",
      "Review 1511 - Label: 1 (Positive))\n",
      "There were times when this movie seemed to get a whole lot more complicated than it needed to be, but I guess that's part of it's charm. Detective Philo Vance's powers of observation seem greater than all the Oriental sleuths of the era combined when it comes down to that final evaluation of how the murders were committed. The dropping of the dagger into the Chinese vase was the kicker for me; I mean, couldn't somebody have just dropped it? <br /><br />Vance (William Powell) had a line early in the film about Archer Coe's 'psychological impossibility' to kill himself - I had to think about that for a while. I was left wondering if there's some scientific basis in fact for that concept to be true, not having studied psychology myself. Seems logical, but then there's always the case that doesn't fit the rules.<br /><br />You know, I got a kick out of the agitated coroner (Etienne Girardot), who reminded me of Star Trek's Dr. McCoy the couple of times he stated \"I'm a doctor, not a magician\" and \"I'm a doctor, not a detective\". I can picture DeForrest Kelley watching the film and saying to himself - 'I'll have to use that sometime'.<br /><br />Once the killer's identity is revealed, it doesn't seem like such a big surprise, but up till then it's really anybody's guess. But Archer and Brisbane Coe aside, the film didn't answer the central question posed by the title, and the murder I was really interested in - who killed Sir Thomas MacDonald's dog Ghillie?\n",
      "\n",
      "Review 27594 - Label: 1 (Positive))\n",
      "I remember seeing the trailer for this film and I absolutely knew I had to see this movie. It looked like something that would be right up my alley.<br /><br />\"The United States of Leland\" is a terrific movie. It is not one that will leave you with a nice, pleasant ending, but with a sad, empty feeling instead. And when I say it will leave you with an \"empty\" feeling, I do not mean that as a bad thing. I believe that you are meant to fill that empty feeling with your own thoughts about the characters and human's general motives and how they act as parts of society.<br /><br />Ryan Gosling is perfectly cast as Leland. He is intelligent, yet stoic. I like the way that he narrates the film with his journal. The supporting cast is terrific as well. Kevin Spacey is very good, as always, and Don Cheadle is amazing as Leland's teacher and mentor. <br /><br />This was a great story and is very smart and thought provoking. I highly recommend it.\n",
      "\n",
      "Review 16850 - Label: 1 (Positive))\n",
      "I really enjoyed the pilot, it was as amazing as I hoped it would be, if not better. Patrick Warburton was a riot, although at first i thought that I wouldn't be able to stand his character. Him and Megyn Price Had little chemistry at all, but hopefully as the season goes on they'll get more comfortable around each other. It must have been weird for Megyn to go from being the star on her last show [\"Grounded For Life\"] to being a co-star. <br /><br />Bianca Kajlich and Oliver Hudson seem really new to the whole Sitcom scene, but I think in time they'll get better. David Spade's character, to my surprise, wasn't the whole focus of this pilot. The way he delivers his lines is so different from anyone else i've ever seen on TV, but I think that it is just his style. It works for him.<br /><br />I think that couples, or even singles, will be able to relate to all the doubts and fights and being unsure about your decisions, that this show is about. All the situations that the characters are put in just feel like real life, not sugar-coated like most shows.<br /><br />I hope for all the actors sakes that CBS gives them a chance. This show has the potential to be one of the best series, if just given the chance and time.\n",
      "\n",
      "Review 12280 - Label: 1 (Positive))\n",
      "Jackie Chan is considered by many film and martial arts movie fans as one of the greatest action stars ever to grace the silver screen and Police Story cemented his reputation as the likely successor to the late, great Bruce Lee. If Enter The Dragon bared the so-called bench mark of Lee's greatness in the 70s, then the same can be said about Police Story and Jackie Chan in the 80s.<br /><br />Forget about the Rush Hour trilogy, or any of his US efforts- the one film that really typifies Chan's excellence, not to mention kick starting his status as a high kicking, bone-crushing kung- fu talisman, as well as his movie career was this, Police Story- the first in a series of successful cop films, set in mainland, present day Hong Kong.<br /><br />I've seen many of his efforts- likewise the US-based Rush Hour, Rumble in the Bronx, The Medalian and The Tuxedo to name- and frankly many of them pale into insignificance compared to Police Story. In those movies, we saw a less 'dumbed down' version of Jackie, of whom didn't get the opportunity to utilise his fighting abilities to the maximum, not to mention the fight sequences were no where as good as those in such efforts as Drunken Master, Police Story to name. <br /><br />The stunts in this movie are extraordinary and are the best featured in any action movie. The shopping mall scene is literally one of a kind and has to be seen to be believed: the flying shards of glass, Chan who is left dangling outside the bus only by his walking stick as a madman frantically drives through the streets of the town, and Chan successfully making usage of all sorts of inanimate objects and prop devices as weapons to fight the bad guys with. <br /><br />Considering he is known for injuring and breaking every bone in his body and putting himself in harm's way, Jackie's persistence in showing his versatility as a stuntman himself by not relying on one, is somewhat of a testament to his reputation as a kung fu expert. Especially as he has the bruises to show for it. Thus, he has proved that he is no one-trick pony when it comes down to devising and coming up with various and clever looking moves.<br /><br />Story-wise, there is not much to discuss but what it lacks in narrative, it makes up with its end-to end action and fight sequences. As for the dialogue, well it's not a really huge aspect of the film- which is why most fans of Jackie's and martial arts films are more interested in action, as opposed to the story.<br /><br />Unlike say The Matrix, there are no wires or CGI, or any form of computer trickery involved. What you see is what you get- and what you get with Police Story is a great Jackie Chan epic, full of action and pulsating stunts.It is miles better than Rumble In The Bronx, Rush Hour and all his other American efforts.<br /><br />Police Story is an excellent film and one I'd definitely recommend to anyone who is a novice Jackie Chan fan, but of whom are unsure which one they should watch first.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at a random selection of 5 reviews and the labels they're given.\n",
    "# Every time re-run this cell, you'll see 5 different randomly selected reviews\n",
    "for idx, row in df.sample(n=5).iterrows():\n",
    "    print(f\"Review {idx} - Label: {row['label']} ({'Negative' if row['label'] == 0 else 'Positive'}))\")\n",
    "    print(f\"{row['text']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 32000 texts and 32000 labels in the training set.\n",
      "There are 8000 texts and 8000 labels in the test set\n"
     ]
    }
   ],
   "source": [
    "# Split into training and test data - there's a scikit-learn function for that, import it here:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# From googling, I know that this 'train_test_split' expects us to have a list of texts (we'll call that 'X')\n",
    "# and a list of labels (which we'll call 'Y'), so I will set that up first:\n",
    "X = df['text'] # Meaning: our 'X' data is the list of all the stuff in the 'text' column from our DataFrame\n",
    "Y = df['label'] # As above, but with the 0 or 1 labels\n",
    "\n",
    "# 'train_test_split' needs us to tell it what percent of the data we should extract and put in the TEST set,\n",
    "# and we will also set a parameter called 'random_state' - when train_test_split splits up the data, it will\n",
    "# pick randomly from positive/negative reviews - but we want this to give us the same results every time we run it,\n",
    "# and giving a number as a 'random_state' will make it pick 'randomly' (ish) in a reproducible way.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=195) # The 'test_size' here means: withhold 20% of the data for testing\n",
    "\n",
    "print(f\"There are {len(X_train)} texts and {len(Y_train)} labels in the training set.\")\n",
    "print(f\"There are {len(X_test)} texts and {len(Y_test)} labels in the test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This should be (32000, 84966):  (32000, 84966)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "X_train_counts = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Print out what the result looks like via its '.shape' property.\n",
    "# The first number in the .shape is the number of inputs, and the second number is the number of things (words, for us) it found in those inputs.\n",
    "print(f\"This should be (32000, 84966):  {X_train_counts.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This should be the same numbers we got before:\n",
      "(32000, 84966)\n"
     ]
    }
   ],
   "source": [
    "# Import the TF-IDF tool after googling how to use it:\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Make an instance of the TfidfTransformer and have it 'fit' to our 'X_train_counts' processed data, and\n",
    "# use that information to make a 'transformer' called tf_transformer that can use to 'transform' any document\n",
    "# into the same kind of format:\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "# Make training data, but using the TF-IDF approach rather than just counts:\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "print(\"This should be the same numbers we got before:\")\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll try Logistic Regression first and see if it works at all.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Try these later by setting 'trial_model' to be one of these (see cells after this one) rather than 'LogisticRegression'\"assignment 1 submissions\"\n",
    "# - the names of the models are on the right / they are the things you're importing!\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier # Stochastic Graident Descent classifier - slightly more advanced, but will it work better? \n",
    "from sklearn.naive_bayes import GaussianNB # \"Gaussian Naïve Bayes\" - uses Bayes' theorem; might work better on our tf-idf text data...\n",
    "from sklearn.naive_bayes import MultinomialNB # \"Multinomial Naive Bayes\" - in theory, it can work well on tf-idf text stuff like ours. We'll find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_model = LogisticRegression() # change this later using the same kind of formatting to try different models.\n",
    "\n",
    "# Remember: we transformed our original X_train data into something called 'X_train_tfidf'\n",
    "# but the labels (Y_train) are still the same.\n",
    "\n",
    "# a little code here to change the input to a .toarray() form *IF* the model is GaussianNB, because GaussianNB\n",
    "# expects a slightly different input format.\n",
    "trial_model.fit(X_train_tfidf.toarray() if isinstance(trial_model, GaussianNB) else X_train_tfidf, Y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our test data to the right format by using our 'tfidf_transformer' to process the X_test texts.\n",
    "# But we need to do all the stuff we did to the training data, too - we have to first convert the text to\n",
    "# counts, using our 'count_vectorizer' - THEN give those counts to the tfidf transformer!\n",
    "X_test_counts = count_vectorizer.transform(X_test)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now: let's get some predictions from our model!\n",
    "test_predictions = trial_model.predict(X_test_tfidf.toarray() if isinstance(trial_model, GaussianNB) else X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance report using <class 'sklearn.linear_model._logistic.LogisticRegression'> model:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Negative (0)       0.91      0.88      0.89      4075\n",
      "Positive (1)       0.88      0.91      0.89      3925\n",
      "\n",
      "    accuracy                           0.89      8000\n",
      "   macro avg       0.89      0.89      0.89      8000\n",
      "weighted avg       0.89      0.89      0.89      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the 'metrics' library from sklearn, that's what we need to make our performance report\n",
    "from sklearn import metrics \n",
    "\n",
    "# Make a classification report from our test_predictions and the Y_test labels, which are the 'truth':\n",
    "report = metrics.classification_report(Y_test, test_predictions, target_names = ['Negative (0)', 'Positive (1)'])\n",
    "\n",
    "print(f\"Performance report using {type(trial_model)} model:\\n\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_reviews = {\n",
    "    \"<hey i absolutely hate this movie cause it is so good and i could NOT stop thinking about it for the rest of the day>\": 1,\n",
    "    \n",
    "    \"<I really like the storyline of this movie>\": 1,\n",
    "    \"<I really love the storyline of this movie>\": 1,\n",
    "    \"<this is something i like, just like a chocolate ice cream in the summer>\": 1,\n",
    "    \"<it was like watching an old grandma show, but i like it>\": 1,\n",
    "\n",
    "    \"<the lighting was very clear and really helped the audience develop a immersive feeling while watching it>\": 1,\n",
    "    \"<the lighting was clear and helped the audience develop a immersive feeling while watching it>\": 1,\n",
    "    \"<the lighting was very clear and helped the audience develop a immersive feeling while watching it>\": 1,\n",
    "    \"<the lighting was clear and really helped the audience develop a immersive feeling while watching it>\": 1,\n",
    "\n",
    "    \"<This movie is so weird but this also makes it very interesting to watch. Some part of it is so unexpected but fantastic>\": 1,\n",
    "    \"<this is pretty cliche>\": 0,\n",
    "\n",
    "    \"<it's so cool>\": 1,\n",
    "    \"<IT'S SO COOL>\": 1,\n",
    "    \"<i did not understand what is going on>\": 0,\n",
    "    \"<I DID NOT UNDERSTAND WHAT IS GOING ON>\": 0,\n",
    "\n",
    "    \"<it is so complex and hard to understand>\": 0,\n",
    "    \"<I have to say, i like the first season a lot better...what happened???>\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1:\n",
      "<hey i absolutely hate this movie cause it is so good and i could NOT stop thinking about it for the rest of the day>\n",
      "\tModel predicted: Negative (0) - My label: Positive (1)\n",
      "\tThe model failed!\n",
      "\n",
      "Review 2:\n",
      "<I really like the storyline of this movie>\n",
      "\tModel predicted: Negative (0) - My label: Positive (1)\n",
      "\tThe model failed!\n",
      "\n",
      "Review 3:\n",
      "<I really love the storyline of this movie>\n",
      "\tModel predicted: Positive (1) - My label: Positive (1)\n",
      "\tThe model succeeded!\n",
      "\n",
      "Review 4:\n",
      "<this is something i like, just like a chocolate ice cream in the summer>\n",
      "\tModel predicted: Negative (0) - My label: Positive (1)\n",
      "\tThe model failed!\n",
      "\n",
      "Review 5:\n",
      "<it was like watching an old grandma show, but i like it>\n",
      "\tModel predicted: Negative (0) - My label: Positive (1)\n",
      "\tThe model failed!\n",
      "\n",
      "Review 6:\n",
      "<the lighting was very clear and really helped the audience develop a immersive feeling while watching it>\n",
      "\tModel predicted: Positive (1) - My label: Positive (1)\n",
      "\tThe model succeeded!\n",
      "\n",
      "Review 7:\n",
      "<the lighting was clear and helped the audience develop a immersive feeling while watching it>\n",
      "\tModel predicted: Negative (0) - My label: Positive (1)\n",
      "\tThe model failed!\n",
      "\n",
      "Review 8:\n",
      "<the lighting was very clear and helped the audience develop a immersive feeling while watching it>\n",
      "\tModel predicted: Positive (1) - My label: Positive (1)\n",
      "\tThe model succeeded!\n",
      "\n",
      "Review 9:\n",
      "<the lighting was clear and really helped the audience develop a immersive feeling while watching it>\n",
      "\tModel predicted: Negative (0) - My label: Positive (1)\n",
      "\tThe model failed!\n",
      "\n",
      "Review 10:\n",
      "<This movie is so weird but this also makes it very interesting to watch. Some part of it is so unexpected but fantastic>\n",
      "\tModel predicted: Positive (1) - My label: Positive (1)\n",
      "\tThe model succeeded!\n",
      "\n",
      "Review 11:\n",
      "<this is pretty cliche>\n",
      "\tModel predicted: Negative (0) - My label: Negative (0)\n",
      "\tThe model succeeded!\n",
      "\n",
      "Review 12:\n",
      "<it's so cool>\n",
      "\tModel predicted: Positive (1) - My label: Positive (1)\n",
      "\tThe model succeeded!\n",
      "\n",
      "Review 13:\n",
      "<IT'S SO COOL>\n",
      "\tModel predicted: Positive (1) - My label: Positive (1)\n",
      "\tThe model succeeded!\n",
      "\n",
      "Review 14:\n",
      "<i did not understand what is going on>\n",
      "\tModel predicted: Negative (0) - My label: Negative (0)\n",
      "\tThe model succeeded!\n",
      "\n",
      "Review 15:\n",
      "<I DID NOT UNDERSTAND WHAT IS GOING ON>\n",
      "\tModel predicted: Negative (0) - My label: Negative (0)\n",
      "\tThe model succeeded!\n",
      "\n",
      "Review 16:\n",
      "<it is so complex and hard to understand>\n",
      "\tModel predicted: Positive (1) - My label: Negative (0)\n",
      "\tThe model failed!\n",
      "\n",
      "Review 17:\n",
      "<I have to say, i like the first season a lot better...what happened???>\n",
      "\tModel predicted: Positive (1) - My label: Negative (0)\n",
      "\tThe model failed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now: let's have our model predict 0 or 1, negative or positive, for the reviews just wrote, and compare to the label:\n",
    "\n",
    "my_texts = my_reviews.keys()\n",
    "\n",
    "# Do the transformations like with the other texts - first count vectors, then tf-idf:\n",
    "texts_as_count_vectors = count_vectorizer.transform(my_texts)\n",
    "texts_as_tfidf_vectors = tfidf_transformer.transform(texts_as_count_vectors)\n",
    "\n",
    "# NOW do the predictions on those vectors:\n",
    "model_predictions = trial_model.predict(texts_as_tfidf_vectors.toarray())\n",
    "\n",
    "\n",
    "for review_num, (review, label) in enumerate(my_reviews.items(), start=1):\n",
    "    this_review_prediction = model_predictions[review_num-1]\n",
    "    print(f\"Review {review_num}:\")\n",
    "    print(review)\n",
    "    print(f\"\\tModel predicted: {'Negative (0)' if this_review_prediction == 0 else 'Positive (1)'} - My label: {'Negative (0)' if label == 0 else 'Positive (1)'}\")\n",
    "    print(f\"\\tThe model {'succeeded' if this_review_prediction == label else 'failed'}!\\n\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
